{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSQFs_G8caeE"
   },
   "source": [
    "# Collab preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "XIVB0Xn1g6ih",
    "outputId": "ae007537-b4e3-49f9-88db-fb3efbbfa59d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "qciH4PsUazL_",
    "outputId": "4cd6812e-cdc5-4b85-ba5c-a6564ed7a8ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJ5taGmPcWV-"
   },
   "source": [
    "# Get the code and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "P3LihClHbUd3",
    "outputId": "63909c35-77da-4716-93d2-2c1f6460bd49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Wav2Lip'...\n",
      "remote: Enumerating objects: 152, done.\u001b[K\n",
      "remote: Counting objects: 100% (152/152), done.\u001b[K\n",
      "remote: Compressing objects: 100% (133/133), done.\u001b[K\n",
      "remote: Total 152 (delta 70), reused 65 (delta 12), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (152/152), 61.62 KiB | 12.32 MiB/s, done.\n",
      "Resolving deltas: 100% (70/70), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Rudrabha/Wav2Lip.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "y-19nzx8SamJ",
    "outputId": "0b4759a1-44d6-41a7-f747-cac90f3884fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdrive\tsample_data  Wav2Lip\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjzMPy_Sb0AI"
   },
   "outputs": [],
   "source": [
    "!cp -ri \"/content/gdrive/My Drive/Wav2lip/wav2lip_gan.pth\" /content/Wav2Lip/checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWTaOS3ncFt6"
   },
   "source": [
    "# Get the pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "Ooh28vw-Uvd3",
    "outputId": "2c217dbd-8e82-465a-ef48-c358d4cff387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling tensorflow-2.3.0:\n",
      "  Would remove:\n",
      "    /usr/local/bin/estimator_ckpt_converter\n",
      "    /usr/local/bin/saved_model_cli\n",
      "    /usr/local/bin/tensorboard\n",
      "    /usr/local/bin/tf_upgrade_v2\n",
      "    /usr/local/bin/tflite_convert\n",
      "    /usr/local/bin/toco\n",
      "    /usr/local/bin/toco_from_protos\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.3.0.dist-info/*\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
      "Proceed (y/n)? y\n",
      "  Successfully uninstalled tensorflow-2.3.0\n",
      "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "49dCYlLdcK2D",
    "outputId": "93ef3744-9ad3-47ab-c20d-211539fda66e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa==0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/6e/0eb0de1c9c4e02df0b40e56f258eb79bd957be79b918511a184268e01720/librosa-0.7.0.tar.gz (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 5.1MB/s \n",
      "\u001b[?25hCollecting numpy==1.17.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/92/57179ed45307ec6179e344231c47da7f3f3da9e2eee5c8ab506bd279ce4e/numpy-1.17.1-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n",
      "\u001b[K     |████████████████████████████████| 20.4MB 6.7MB/s \n",
      "\u001b[?25hCollecting opencv-contrib-python==4.2.0.34\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/db/790dbc6bcfea87fc6f790c6306509c2691ce31c96d82e5b826545d90ea52/opencv_contrib_python-4.2.0.34-cp36-cp36m-manylinux1_x86_64.whl (34.2MB)\n",
      "\u001b[K     |████████████████████████████████| 34.2MB 65kB/s \n",
      "\u001b[?25hCollecting opencv-python==4.1.0.25\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/d2/a2dbf83d4553ca6b3701d91d75e42fe50aea97acdc00652dca515749fb5d/opencv_python-4.1.0.25-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\n",
      "\u001b[K     |████████████████████████████████| 26.6MB 115kB/s \n",
      "\u001b[?25hCollecting tensorflow==1.12.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
      "\u001b[K     |████████████████████████████████| 83.1MB 40kB/s \n",
      "\u001b[?25hCollecting torch==1.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/60/f685fb2cfb3088736bafbc9bdbb455327bdc8906b606da9c9a81bae1c81e/torch-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (676.9MB)\n",
      "\u001b[K     |████████████████████████████████| 676.9MB 26kB/s \n",
      "\u001b[?25hCollecting torchvision==0.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/45/0f2f3062c92d9cf1d5d7eabd3cae88cea9affbd2b17fb1c043627838cb0a/torchvision-0.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.6MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6MB 46.4MB/s \n",
      "\u001b[?25hCollecting tqdm==4.45.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/1c/6359be64e8301b84160f6f6f7936bbfaaa5e9a4eab6cbc681db07600b949/tqdm-4.45.0-py2.py3-none-any.whl (60kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 9.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (2.1.8)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (4.4.2)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (0.48.0)\n",
      "Collecting soundfile>=0.9.0\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 5)) (1.31.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 5)) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 5)) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 5)) (3.12.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 5)) (0.35.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 5)) (0.8.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 5)) (0.3.3)\n",
      "Collecting tensorboard<1.13.0,>=1.12.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1MB 45.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 5)) (1.1.0)\n",
      "Collecting keras-applications>=1.0.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0->-r requirements.txt (line 7)) (7.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa==0.7.0->-r requirements.txt (line 1)) (49.6.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa==0.7.0->-r requirements.txt (line 1)) (0.31.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa==0.7.0->-r requirements.txt (line 1)) (1.14.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->-r requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->-r requirements.txt (line 5)) (3.2.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0->-r requirements.txt (line 5)) (2.10.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.0->-r requirements.txt (line 1)) (2.20)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->-r requirements.txt (line 5)) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->-r requirements.txt (line 5)) (3.1.0)\n",
      "Building wheels for collected packages: librosa\n",
      "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for librosa: filename=librosa-0.7.0-cp36-none-any.whl size=1598345 sha256=681428afdbc5568b9b732341dd39b999be05e93a9306d4d8d55651c056612563\n",
      "  Stored in directory: /root/.cache/pip/wheels/49/1d/38/c8ad12fcad67569d8e730c3275be5e581bd589558484a0f881\n",
      "Successfully built librosa\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, soundfile, librosa, opencv-contrib-python, opencv-python, tensorboard, keras-applications, tensorflow, torch, torchvision, tqdm\n",
      "  Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "  Found existing installation: librosa 0.6.3\n",
      "    Uninstalling librosa-0.6.3:\n",
      "      Successfully uninstalled librosa-0.6.3\n",
      "  Found existing installation: opencv-contrib-python 4.1.2.30\n",
      "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
      "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
      "  Found existing installation: opencv-python 4.1.2.30\n",
      "    Uninstalling opencv-python-4.1.2.30:\n",
      "      Successfully uninstalled opencv-python-4.1.2.30\n",
      "  Found existing installation: tensorboard 2.3.0\n",
      "    Uninstalling tensorboard-2.3.0:\n",
      "      Successfully uninstalled tensorboard-2.3.0\n",
      "  Found existing installation: torch 1.6.0+cu101\n",
      "    Uninstalling torch-1.6.0+cu101:\n",
      "      Successfully uninstalled torch-1.6.0+cu101\n",
      "  Found existing installation: torchvision 0.7.0+cu101\n",
      "    Uninstalling torchvision-0.7.0+cu101:\n",
      "      Successfully uninstalled torchvision-0.7.0+cu101\n",
      "  Found existing installation: tqdm 4.41.1\n",
      "    Uninstalling tqdm-4.41.1:\n",
      "      Successfully uninstalled tqdm-4.41.1\n",
      "Successfully installed keras-applications-1.0.8 librosa-0.7.0 numpy-1.17.1 opencv-contrib-python-4.2.0.34 opencv-python-4.1.0.25 soundfile-0.10.3.post1 tensorboard-1.12.2 tensorflow-1.12.0 torch-1.1.0 torchvision-0.3.0 tqdm-4.45.0\n"
     ]
    }
   ],
   "source": [
    "!cd Wav2Lip && pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "id": "ey_bN4M6X_95",
    "outputId": "91186c66-f7da-49ae-a91d-34fa98e43555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-12 20:06:29--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
      "Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n",
      "Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 89843225 (86M) [application/octet-stream]\n",
      "Saving to: ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’\n",
      "\n",
      "Wav2Lip/face_detect 100%[===================>]  85.68M  16.5MB/s    in 6.3s    \n",
      "\n",
      "2020-09-12 20:06:36 (13.7 MB/s) - ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdIQfY2Kswcb"
   },
   "source": [
    "# Now lets try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "KoVGMtjRZfeR",
    "outputId": "eafe1600-72e3-4936-e28f-c7d6a8a06a6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anscombe.json\t\t      input_audio.wav  mnist_train_small.csv\n",
      "california_housing_test.csv   input_video.mp4  README.md\n",
      "california_housing_train.csv  mnist_test.csv\n"
     ]
    }
   ],
   "source": [
    "!cp \"/content/gdrive/My Drive/Wav2Lip/input_video.mp4\" \"/content/gdrive/My Drive/Wav2Lip/input_audio.wav\" sample_data/\n",
    "!ls sample_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jR5utmDMcSZY",
    "outputId": "cc4b7cb2-25f4-4ae4-e4dd-f9fa4c71c242"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using cuda for inference.\n",
      "Reading video frames...\n",
      "Number of frames available for inference: 479\n",
      "(80, 2321)\n",
      "Length of mel chunks: 866\n",
      "  0% 0/7 [00:00<?, ?it/s]\n",
      "  0% 0/30 [00:00<?, ?it/s]\u001b[ATHCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=383 error=11 : invalid argument\n",
      "  0% 0/30 [00:02<?, ?it/s]\n",
      "Recovering from OOM error; New batch size: 8\n",
      "\n",
      "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 1/60 [00:14<14:28, 14.72s/it]\u001b[A\n",
      "  3% 2/60 [00:17<10:47, 11.17s/it]\u001b[A\n",
      "  5% 3/60 [00:20<08:09,  8.58s/it]\u001b[A\n",
      "  7% 4/60 [00:22<06:18,  6.76s/it]\u001b[A\n",
      "  8% 5/60 [00:25<05:02,  5.50s/it]\u001b[A\n",
      " 10% 6/60 [00:27<04:08,  4.61s/it]\u001b[A\n",
      " 12% 7/60 [00:30<03:31,  3.99s/it]\u001b[A\n",
      " 13% 8/60 [00:32<03:04,  3.56s/it]\u001b[A\n",
      " 15% 9/60 [00:35<02:46,  3.26s/it]\u001b[A\n",
      " 17% 10/60 [00:37<02:32,  3.05s/it]\u001b[A\n",
      " 18% 11/60 [00:40<02:22,  2.90s/it]\u001b[A\n",
      " 20% 12/60 [00:43<02:14,  2.79s/it]\u001b[A\n",
      " 22% 13/60 [00:45<02:08,  2.73s/it]\u001b[A\n",
      " 23% 14/60 [00:48<02:03,  2.67s/it]\u001b[A\n",
      " 25% 15/60 [00:50<01:58,  2.64s/it]\u001b[A\n",
      " 27% 16/60 [00:53<01:54,  2.61s/it]\u001b[A\n",
      " 28% 17/60 [00:55<01:51,  2.59s/it]\u001b[A\n",
      " 30% 18/60 [00:58<01:48,  2.58s/it]\u001b[A\n",
      " 32% 19/60 [01:00<01:45,  2.57s/it]\u001b[A\n",
      " 33% 20/60 [01:03<01:42,  2.57s/it]\u001b[A\n",
      " 35% 21/60 [01:06<01:40,  2.57s/it]\u001b[A\n",
      " 37% 22/60 [01:08<01:37,  2.57s/it]\u001b[A\n",
      " 38% 23/60 [01:11<01:35,  2.57s/it]\u001b[A\n",
      " 40% 24/60 [01:13<01:32,  2.56s/it]\u001b[A\n",
      " 42% 25/60 [01:16<01:29,  2.56s/it]\u001b[A\n",
      " 43% 26/60 [01:18<01:27,  2.56s/it]\u001b[A\n",
      " 45% 27/60 [01:21<01:24,  2.56s/it]\u001b[A\n",
      " 47% 28/60 [01:24<01:22,  2.56s/it]\u001b[A\n",
      " 48% 29/60 [01:26<01:19,  2.56s/it]\u001b[A\n",
      " 50% 30/60 [01:29<01:16,  2.56s/it]\u001b[A\n",
      " 52% 31/60 [01:31<01:14,  2.57s/it]\u001b[A\n",
      " 53% 32/60 [01:34<01:12,  2.57s/it]\u001b[A\n",
      " 55% 33/60 [01:36<01:09,  2.58s/it]\u001b[A\n",
      " 57% 34/60 [01:39<01:07,  2.58s/it]\u001b[A\n",
      " 58% 35/60 [01:42<01:04,  2.58s/it]\u001b[A\n",
      " 60% 36/60 [01:44<01:02,  2.59s/it]\u001b[A\n",
      " 62% 37/60 [01:47<00:59,  2.59s/it]\u001b[A\n",
      " 63% 38/60 [01:49<00:56,  2.59s/it]\u001b[A\n",
      " 65% 39/60 [01:52<00:54,  2.58s/it]\u001b[A\n",
      " 67% 40/60 [01:55<00:51,  2.59s/it]\u001b[A\n",
      " 68% 41/60 [01:57<00:49,  2.59s/it]\u001b[A\n",
      " 70% 42/60 [02:00<00:46,  2.58s/it]\u001b[A\n",
      " 72% 43/60 [02:02<00:43,  2.58s/it]\u001b[A\n",
      " 73% 44/60 [02:05<00:41,  2.59s/it]\u001b[A\n",
      " 75% 45/60 [02:07<00:38,  2.59s/it]\u001b[A\n",
      " 77% 46/60 [02:10<00:36,  2.59s/it]\u001b[A\n",
      " 78% 47/60 [02:13<00:33,  2.58s/it]\u001b[A\n",
      " 80% 48/60 [02:15<00:31,  2.59s/it]\u001b[A\n",
      " 82% 49/60 [02:18<00:28,  2.58s/it]\u001b[A\n",
      " 83% 50/60 [02:20<00:25,  2.59s/it]\u001b[A\n",
      " 85% 51/60 [02:23<00:23,  2.59s/it]\u001b[A\n",
      " 87% 52/60 [02:26<00:20,  2.59s/it]\u001b[A\n",
      " 88% 53/60 [02:28<00:18,  2.59s/it]\u001b[A\n",
      " 90% 54/60 [02:31<00:15,  2.59s/it]\u001b[A\n",
      " 92% 55/60 [02:33<00:12,  2.60s/it]\u001b[A\n",
      " 93% 56/60 [02:36<00:10,  2.60s/it]\u001b[A\n",
      " 95% 57/60 [02:39<00:07,  2.60s/it]\u001b[A\n",
      " 97% 58/60 [02:41<00:05,  2.60s/it]\u001b[A\n",
      " 98% 59/60 [02:44<00:02,  2.61s/it]\u001b[A\n",
      "100% 60/60 [02:59<00:00,  2.99s/it]\n",
      "Load checkpoint from: checkpoints/wav2lip_gan.pth\n",
      "Model loaded\n",
      "100% 7/7 [03:37<00:00, 31.08s/it]\n",
      "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : stereo\n",
      "\u001b[0mInput #0, wav, from '../sample_data/input_audio.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:29.00, bitrate: 1411 kb/s\n",
      "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Input #1, avi, from 'temp/result.avi':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.26.101\n",
      "  Duration: 00:00:28.87, start: 0.000000, bitrate: 3323 kb/s\n",
      "    Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 3318 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
      "Stream mapping:\n",
      "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n",
      "\u001b[0m\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mprofile High, level 4.0\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'results/result_voice.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 1920x1080 [SAR 1:1 DAR 16:9], q=-1--1, 30 fps, 15360 tbn, 30 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc57.107.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "    Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc57.107.100 aac\n",
      "frame=  866 fps= 13 q=-1.0 Lsize=    6474kB time=00:00:29.00 bitrate=1828.8kbits/s speed=0.451x    \n",
      "video:5988kB audio:456kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.481710%\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mframe I:4     Avg QP:16.77  size: 43724\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mframe P:367   Avg QP:20.01  size: 11981\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mframe B:495   Avg QP:22.55  size:  3149\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mconsecutive B-frames: 15.6% 18.7% 17.7% 48.0%\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mmb I  I16..4: 43.7% 52.9%  3.4%\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mmb P  I16..4:  4.3% 10.1%  0.1%  P16..4: 23.2%  3.6%  1.4%  0.0%  0.0%    skip:57.2%\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mmb B  I16..4:  0.3%  0.6%  0.0%  B16..8: 26.4%  0.8%  0.0%  direct: 0.9%  skip:71.0%  L0:53.6% L1:45.6% BI: 0.8%\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0m8x8 transform intra:68.4% inter:92.1%\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mcoded y,uvDC,uvAC intra: 25.5% 42.6% 5.7% inter: 2.4% 5.2% 0.1%\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mi16 v,h,dc,p: 69% 20%  8%  3%\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 40% 19% 37%  1%  0%  1%  0%  1%  1%\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 59% 19% 10%  2%  3%  3%  2%  2%  1%\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mi8c dc,h,v,p: 38% 20% 39%  3%\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mref P L0: 70.5%  6.4% 16.3%  6.8%\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mref B L0: 74.4% 21.1%  4.5%\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mref B L1: 95.1%  4.9%\n",
      "\u001b[1;36m[libx264 @ 0x55fe1f142d00] \u001b[0mkb/s:1699.02\n",
      "\u001b[1;36m[aac @ 0x55fe1f17e000] \u001b[0mQavg: 532.126\n"
     ]
    }
   ],
   "source": [
    "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/input_video.mp4\" --audio \"../sample_data/input_audio.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uNOAZvkszEOw"
   },
   "outputs": [],
   "source": [
    "# use the \"files\" button on the left to download the result in the Wav2Lip/results/ folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7zgfrQqbKom"
   },
   "source": [
    "## **Variations to try**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f9A9VDVbZAG"
   },
   "source": [
    "1.   Use more padding to include the chin region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45XW4SZAzIz5"
   },
   "outputs": [],
   "source": [
    "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/input_video.mp4\" --audio \"../sample_data/input_audio.wav\" --pads 0 20 0 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo-WnsxfbwTG"
   },
   "source": [
    "2.   Use resize_factor to reduce the video resolution, as there is a change you might get better results for lower resolution videos. Why? Because the model was trained on low resolution faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xw0xFtZ2bsx8"
   },
   "outputs": [],
   "source": [
    "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/input_video.mp4\" --audio \"../sample_data/input_audio.wav\" --resize_factor 2"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DeepFake Wav2Lip_quick_trial.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
